{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5617e344-c0c0-4bd9-a663-3cbb48c42afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from implementations import *\n",
    "from helpers import *\n",
    "from helper_functions import *\n",
    "from optimization import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8dc3d956-5298-48d9-80ea-28ab9505cf2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the training dataset\n",
    "print(\"loading the training dataset\")\n",
    "DATA_TRAIN_PATH = 'train.csv'\n",
    "y_tr, tx_tr, ids_tr = load_csv_data(DATA_TRAIN_PATH)\n",
    "print(\"training dataset loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e34d96-8369-45f9-b2d0-5be13dd045ff",
   "metadata": {},
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1dbf9868-2009-40c7-b006-4d49fabb9723",
   "metadata": {},
   "outputs": [],
   "source": [
    "txOpti, yOpti, _ = dataClean(tx_tr, y_tr)\n",
    "print(\"preprocessing done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd001160-20fd-437f-854a-118735019b0a",
   "metadata": {},
   "source": [
    "# Train using regularized logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b9bed508-67dc-437a-a1fc-c7c1324a9dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of txOpti[0]  (99913, 19)\n",
      "Current iteration=0\t the loss=0.6820645\t the grad=1.2101687\n",
      "Current iteration=25\t the loss=-6.3559725\t the grad=0.7207940\n",
      "Current iteration=50\t the loss=-12.9875557\t the grad=0.7172199\n",
      "Current iteration=75\t the loss=-19.6002879\t the grad=0.7164339\n",
      "Current iteration=100\t the loss=-26.2078541\t the grad=0.7161297\n",
      "Current iteration=125\t the loss=-32.8132364\t the grad=0.7159748\n",
      "Current iteration=150\t the loss=-39.4174291\t the grad=0.7158810\n",
      "Current iteration=175\t the loss=-46.0208530\t the grad=0.7158168\n",
      "end of the reg_logistic_regression with w= [-63.85078519   4.6310616  -14.8356007    8.35828419   0.329194\n",
      "   9.5817948    0.32919392   8.40253678 -15.33737058  -2.44006942\n",
      "  10.16364922   0.18668227  -0.33677372  -5.58487578   1.27387192\n",
      "   0.16613606 -17.23337788  -0.17983268   4.40592765]  and loss= -52.359612181782566\n",
      "shape of txOpti[1]  (77544, 23)\n",
      "Current iteration=0\t the loss=0.7654166\t the grad=1.0116634\n",
      "Current iteration=25\t the loss=-3.3638025\t the grad=0.5368403\n",
      "Current iteration=50\t the loss=-7.0754947\t the grad=0.5304236\n",
      "Current iteration=75\t the loss=-10.7600279\t the grad=0.5290209\n",
      "Current iteration=100\t the loss=-14.4366964\t the grad=0.5284902\n",
      "Current iteration=125\t the loss=-18.1100190\t the grad=0.5282290\n",
      "Current iteration=150\t the loss=-21.7816027\t the grad=0.5280780\n",
      "Current iteration=175\t the loss=-25.4521546\t the grad=0.5279803\n",
      "end of the reg_logistic_regression with w= [-4.46184306e+01  1.36936344e+01 -1.73407946e+01  8.41090240e+00\n",
      "  2.68276105e+00  1.50885892e+00  1.98833652e+00  3.79082250e+00\n",
      " -8.48739559e+00  1.21311481e+01  8.12078282e+00 -2.90335686e-01\n",
      " -1.16515882e-01 -7.10177668e-01 -5.47298339e-01  4.93100672e-01\n",
      " -2.41897389e+00  3.63297834e-01  3.10370569e+00  2.95953374e+00\n",
      " -3.86266150e-01 -1.82581346e-02  2.95953410e+00]  and loss= -28.975245147787884\n",
      "shape of txOpti[2]  (50379, 30)\n",
      "Current iteration=0\t the loss=0.6961193\t the grad=0.9719781\n",
      "Current iteration=25\t the loss=-1.9203095\t the grad=0.4065326\n",
      "Current iteration=50\t the loss=-4.0955512\t the grad=0.3976049\n",
      "Current iteration=75\t the loss=-6.2408450\t the grad=0.3955109\n",
      "Current iteration=100\t the loss=-8.3775779\t the grad=0.3947021\n",
      "Current iteration=125\t the loss=-10.5106979\t the grad=0.3943039\n",
      "Current iteration=150\t the loss=-12.6419335\t the grad=0.3940766\n",
      "Current iteration=175\t the loss=-14.7720450\t the grad=0.3939330\n",
      "end of the reg_logistic_regression with w= [-2.74125457e+01  1.65897252e+01 -8.14947043e+00  8.84163961e+00\n",
      "  5.26205691e+00  5.07284621e+00  4.09478453e+00 -5.01029188e+00\n",
      "  5.92701280e-01 -5.68472320e+00  1.70096145e+00 -5.20744555e+00\n",
      "  8.83600573e+00  1.34261485e+01  5.69061209e+00 -1.32362985e-01\n",
      "  1.15075588e-01 -6.66286924e-01 -4.26090927e-01 -3.44531391e-02\n",
      "  7.07490141e-01  4.87372486e-01 -1.67981711e+00  2.48903316e+00\n",
      "  5.86812234e-02 -7.44753699e-02  3.10677599e+00 -2.34419529e-02\n",
      " -5.52132775e-01  2.53921069e+00]  and loss= -16.81625702123239\n",
      "shape of txOpti[3]  (22164, 30)\n",
      "Current iteration=0\t the loss=0.8205706\t the grad=0.9944130\n",
      "Current iteration=25\t the loss=-3.3477382\t the grad=0.5436122\n",
      "Current iteration=50\t the loss=-7.1072324\t the grad=0.5386062\n",
      "Current iteration=75\t the loss=-10.8425495\t the grad=0.5375504\n",
      "Current iteration=100\t the loss=-14.5704095\t the grad=0.5371539\n",
      "Current iteration=125\t the loss=-18.2950151\t the grad=0.5369594\n",
      "Current iteration=150\t the loss=-22.0179193\t the grad=0.5368466\n",
      "Current iteration=175\t the loss=-25.7398215\t the grad=0.5367730\n",
      "end of the reg_logistic_regression with w= [-4.75446444e+01  1.69232412e+01 -1.02232988e+01  7.74945605e+00\n",
      "  8.96837383e+00 -1.05685275e+00 -1.12960161e+00 -2.93868824e+00\n",
      " -1.54126526e+00 -2.14663526e+00 -7.43132824e-01 -6.40760997e+00\n",
      "  8.66052563e+00  4.57863951e-01  6.68839745e+00 -1.08203075e+00\n",
      "  1.07113403e-01 -2.63682748e-01  5.10560703e-02  1.51332292e-01\n",
      "  3.43113712e+00  1.19538090e+00 -1.37906759e+00  1.45826631e-01\n",
      " -4.41634814e-01 -5.06820654e-01 -4.51418996e-02  8.67016448e-01\n",
      "  2.81498020e-02 -8.73572104e-01]  and loss= -29.312236118630626\n"
     ]
    }
   ],
   "source": [
    "max_iters = 200\n",
    "gamma = 0.5\n",
    "lambda_ = 1e-06\n",
    "ws = []\n",
    "losses = []\n",
    "\n",
    "for i in range(4): \n",
    "    print(f\"shape of txOpti[{i}] \", txOpti[i].shape)\n",
    "    yOpti[i][np.where(yOpti == -1)] = 0\n",
    "    initial_w = np.zeros(txOpti[i].shape[1])\n",
    "    w, loss = reg_logistic_regression(yOpti[i], txOpti[i], lambda_, initial_w, max_iters, gamma)\n",
    "    ws.append(w)\n",
    "    losses.append(loss)\n",
    "    print(\"end of the reg_logistic_regression with w=\",w,\" and loss=\", loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc904a1-eb1a-4cd7-9ce3-250b6cb99e0a",
   "metadata": {},
   "source": [
    "# Test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f85d1dd-fb25-47e3-8d52-86af32cb5b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "accs = []\n",
    "for i in range(4): \n",
    "    label = predict_logistic(ws[i], txOpti[i])\n",
    "    yOpti[i][np.where(yOpti[i] == 0)] = -1\n",
    "    acc = calculate_accuracy(yOpti[i], label)\n",
    "    print(\"the accuracy on the train set is \", acc)\n",
    "    accs.append(acc)\n",
    "    labels.append(label)\n",
    "\n",
    "accTot = (accs[0] + accs[1] + accs[2] + accs[3])/4\n",
    "print(\"the total accuracy on the train set is \", accTot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43906c4-78b4-4468-bef7-6bd30a66fe9f",
   "metadata": {},
   "source": [
    "# Predict test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ca4e26-4f1a-46e0-9aa6-afed8b349994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the test dataset\n",
    "print(\"loading the test dataset\")\n",
    "DATA_TEST_PATH = 'test.csv'\n",
    "y_te, tx_te, ids_te = load_csv_data(DATA_TEST_PATH)\n",
    "print(\"test dataset loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ce328b-0cdc-4aba-9a81-58ac83ab8983",
   "metadata": {},
   "outputs": [],
   "source": [
    "txOpti_te, yOpti_te, idsOpti_te = dataClean(tx_te, y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3e2a7cf8-fd96-4e26-b6d1-3f13a27203ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.zeros(len(ids_te))\n",
    "\n",
    "for i in range(4):\n",
    "    predicted = predict_logistic(ws[i], txOpti_te[i])\n",
    "    predicted[np.where(predicted == 0)] = -1\n",
    "    y_pred[idsOpti_te[i]] = predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec76993b-8752-49f0-91b9-51cdd346541d",
   "metadata": {},
   "source": [
    "# Generated submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef28071-e6d7-4589-b7c9-35f83cf74996",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH = 'reglr-submission'\n",
    "create_csv_submission(ids_te, y_pred, OUTPUT_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
