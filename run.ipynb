{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "882a9018-5319-4a82-87e7-2b0d420475bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from implementations import *\n",
    "from helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d56f0e3-9ee7-448f-a9dd-dd349209cc8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading the training dataset\n",
      "training dataset loaded\n"
     ]
    }
   ],
   "source": [
    "# load the training dataset\n",
    "print(\"loading the training dataset\")\n",
    "DATA_TRAIN_PATH = 'train.csv'\n",
    "y_tr, tx_tr, ids_tr = load_csv_data(DATA_TRAIN_PATH)\n",
    "print(\"training dataset loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af90503c-e3fa-4e1b-a222-63ef11b39a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading the test dataset\n",
      "test dataset loaded\n"
     ]
    }
   ],
   "source": [
    "# load the test dataset\n",
    "print(\"loading the test dataset\")\n",
    "#DATA_TEST_PATH = 'test.csv'\n",
    "#y_te, tx_te, ids_te = load_csv_data(DATA_TEST_PATH)\n",
    "print(\"test dataset loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa8da103-df5b-4f1e-b595-9ae0cd91750e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the shape of the training y is  (250000,)  and the training tx is  (250000, 30)\n"
     ]
    }
   ],
   "source": [
    "# printing the shapes of the arrays\n",
    "print(\"the shape of the training y is \",y_tr.shape,\" and the training tx is \", tx_tr.shape)\n",
    "#print(\"the shape of the test y is \",y_te.shape,\" and the test tx is \",tx_te.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6884129-6892-4ec8-bce6-fe61104b9ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration=0, the loss=194.24220982964263, the grad=-83.42721036786665\n",
      "Current iteration=1, the loss=615297.5203172743, the grad=4613.174490177686\n",
      "Current iteration=2, the loss=1953508823.7628646, the grad=-259500.53621747566\n",
      "Current iteration=3, the loss=6202205178655.959, the grad=14620755.207659151\n",
      "Current iteration=4, the loss=1.9691413074582136e+16, the grad=-823820866.4070557\n",
      "Current iteration=5, the loss=6.2518368501176074e+19, the grad=46419237311.75828\n",
      "Current iteration=6, the loss=1.9848988923472897e+23, the grad=-2615552042540.125\n",
      "Current iteration=7, the loss=6.301865687309781e+26, the grad=147376670780187.38\n",
      "Current iteration=8, the loss=2.0007825735611232e+30, the grad=-8304129596411834.0\n",
      "Current iteration=9, the loss=6.352294868370608e+33, the grad=4.679069488893871e+17\n",
      "Current iteration=10, the loss=2.0167933601554242e+37, the grad=-2.6364823703546167e+19\n",
      "Current iteration=11, the loss=6.403127596956672e+40, the grad=1.485560175093266e+21\n",
      "Current iteration=12, the loss=2.0329322692607646e+44, the grad=-8.370581418021724e+22\n",
      "Current iteration=13, the loss=6.454367102361035e+47, the grad=4.7165126294080893e+24\n",
      "Current iteration=14, the loss=2.049200326147058e+51, the grad=-2.6575801933509454e+26\n",
      "Current iteration=15, the loss=6.50601663971843e+54, the grad=1.4974480170060748e+28\n",
      "Current iteration=16, the loss=2.0655985642887054e+58, the grad=-8.437565004606856e+29\n",
      "Current iteration=17, the loss=6.558079490212024e+61, the grad=4.754255399750379e+31\n",
      "Current iteration=18, the loss=2.08212802543023e+65, the grad=-2.678846846657131e+33\n",
      "Current iteration=19, the loss=6.610558961281864e+68, the grad=1.5094309885458905e+35\n",
      "Current iteration=20, the loss=2.0987897596524744e+72, the grad=-8.505084611409432e+36\n",
      "Current iteration=21, the loss=6.663458386835004e+75, the grad=4.792300197633999e+38\n",
      "Current iteration=22, the loss=2.115584825439302e+79, the grad=-2.7002836812974393e+40\n",
      "Current iteration=23, the loss=6.716781127457303e+82, the grad=1.5215098509649175e+42\n",
      "Current iteration=24, the loss=2.132514289744842e+86, the grad=-8.573144527803732e+43\n",
      "Current iteration=25, the loss=6.7705305706269e+89, the grad=4.830649439962502e+45\n",
      "Current iteration=26, the loss=2.1495792280612693e+93, the grad=-2.721892059107516e+47\n",
      "Current iteration=27, the loss=6.824710130929427e+96, the grad=1.5336853716071066e+49\n",
      "Current iteration=28, the loss=2.1667807244871272e+100, the grad=-8.641749077488735e+50\n",
      "Current iteration=29, the loss=6.8793232502749156e+103, the grad=4.869305562980134e+52\n",
      "Current iteration=30, the loss=2.184119871796201e+107, the grad=-2.7436733528207676e+54\n",
      "Current iteration=31, the loss=6.93437339811648e+110, the grad=1.5459583239568952e+56\n",
      "Current iteration=32, the loss=2.2015977715069436e+114, the grad=-8.71090261876279e+57\n",
      "Current iteration=33, the loss=6.989864071670689e+117, the grad=4.908271022426614e+59\n",
      "Current iteration=34, the loss=2.2192155339524373e+121, the grad=-2.765628946155577e+61\n",
      "Current iteration=35, the loss=7.045798796139773e+124, the grad=1.5583294876883438e+63\n",
      "Current iteration=36, the loss=2.2369742783509495e+128, the grad=-8.780609544800486e+64\n",
      "Current iteration=37, the loss=7.102181124935548e+131, the grad=4.947548293693122e+66\n",
      "Current iteration=38, the loss=2.254875132877022e+135, the grad=-2.7877602339032043e+68\n",
      "Current iteration=39, the loss=7.159014639905158e+138, the grad=1.570799648714676e+70\n",
      "Current iteration=40, the loss=2.2729192347331441e+142, the grad=-8.85087428393177e+71\n",
      "Current iteration=41, the loss=7.216302951558627e+145, the grad=4.987139871979577e+73\n",
      "Current iteration=42, the loss=2.291107730221997e+149, the grad=-2.8100686220163915e+75\n",
      "Current iteration=43, the loss=7.274049699298234e+152, the grad=1.5833695992381908e+77\n",
      "Current iteration=44, the loss=2.3094417748192826e+156, the grad=-8.921701299923216e+78\n",
      "Current iteration=45, the loss=7.332258551649701e+159, the grad=5.027048272453135e+80\n",
      "Current iteration=46, the loss=2.3279225332471142e+163, the grad=-2.832555527698687e+82\n",
      "Current iteration=47, the loss=7.390933206495257e+166, the grad=1.5960401378006025e+84\n",
      "Current iteration=48, the loss=2.3465511795480196e+170, the grad=-8.993095092261648e+85\n",
      "Current iteration=49, the loss=7.450077391308557e+173, the grad=5.067276030407985e+87\n",
      "Current iteration=50, the loss=2.3653288971595217e+177, the grad=-2.855222379494467e+89\n",
      "Current iteration=51, the loss=7.509694863391474e+180, the grad=1.6088120693337633e+91\n",
      "Current iteration=52, the loss=2.384256878989326e+184, the grad=-9.065060196439946e+92\n",
      "Current iteration=53, the loss=7.569789410112796e+187, the grad=5.107825701426399e+94\n",
      "Current iteration=54, the loss=2.4033363274910948e+191, the grad=-2.8780706173797037e+96\n",
      "Current iteration=55, the loss=7.630364849148838e+194, the grad=1.6216862052108027e+98\n",
      "Current iteration=56, the loss=2.4225684547408355e+198, the grad=-9.13760118424522e+99\n",
      "Current iteration=57, the loss=7.691425028725933e+201, the grad=5.1486998615410915e+101\n",
      "Current iteration=58, the loss=2.4419544825139082e+205, the grad=-2.9011016928534256e+103\n",
      "Current iteration=59, the loss=7.752973827864969e+208, the grad=1.6346633632976697e+105\n",
      "Current iteration=60, the loss=2.4614956423626473e+212, the grad=-9.210722664049186e+106\n",
      "Current iteration=61, the loss=7.815015156627749e+215, the grad=5.189901107398866e+108\n",
      "Current iteration=62, the loss=2.481193175694579e+219, the grad=-2.924317069029943e+110\n",
      "Current iteration=63, the loss=7.877552956365425e+222, the grad=1.647744368005092e+112\n",
      "Current iteration=64, the loss=2.501048333851306e+226, the grad=-9.28442928110098e+113\n",
      "Current iteration=65, the loss=7.940591199968863e+229, the grad=5.2314320564255705e+115\n",
      "Current iteration=66, the loss=2.5210623781879953e+233, the grad=-2.947718220731786e+117\n",
      "Current iteration=67, the loss=8.004133892121064e+236, the grad=1.6609300503409466e+119\n",
      "Current iteration=68, the loss=2.541236580153503e+240, the grad=-9.358725717822244e+120\n",
      "Current iteration=69, the loss=8.068185069551535e+243, the grad=5.273295346992387e+122\n",
      "Current iteration=70, the loss=2.5615722213711524e+247, the grad=-2.9713066345834055e+124\n",
      "Current iteration=71, the loss=8.132748801292747e+250, the grad=1.6742212479630525e+126\n",
      "Current iteration=72, the loss=2.582070593720158e+254, the grad=-9.433616694104557e+127\n",
      "Current iteration=73, the loss=8.197829188938668e+257, the grad=5.31549363858343e+129\n",
      "Current iteration=74, the loss=2.602732999417693e+261, the grad=-2.995083809105608e+131\n",
      "Current iteration=75, the loss=8.263430366905256e+264, the grad=1.687618805232392e+133\n",
      "Current iteration=76, the loss=2.6235607511016017e+268, the grad=-9.50910696760935e+134\n",
      "Current iteration=77, the loss=8.329556502693181e+271, the grad=5.358029611964716e+136\n",
      "Current iteration=78, the loss=2.6445551719138104e+275, the grad=-3.0190512548107595e+138\n",
      "Current iteration=79, the loss=8.396211797152498e+278, the grad=1.7011235732667395e+140\n",
      "Current iteration=80, the loss=2.665717595584364e+282, the grad=-9.585201334070064e+141\n",
      "Current iteration=81, the loss=8.463400484749614e+285, the grad=5.400905969354424e+143\n",
      "Current iteration=82, the loss=2.6870493665161794e+289, the grad=-3.043210494298733e+145\n",
      "Current iteration=83, the loss=8.531126833836234e+292, the grad=1.7147364099947353e+147\n",
      "Current iteration=84, the loss=2.7085518398704265e+296, the grad=-9.661904627596884e+148\n",
      "Current iteration=85, the loss=8.599395146920523e+299, the grad=5.4441254345946204e+150\n",
      "Current iteration=86, the loss=inf, the grad=-3.067563062353656e+152\n",
      "Current iteration=87, the loss=inf, the grad=1.7284581802103947e+154\n",
      "Current iteration=88, the loss=inf, the grad=-9.739221720983801e+155\n",
      "Current iteration=89, the loss=inf, the grad=5.4876907533242566e+157\n",
      "Current iteration=90, the loss=inf, the grad=-3.092110506041396e+159\n",
      "Current iteration=91, the loss=inf, the grad=1.74228975562804e+161\n",
      "Current iteration=92, the loss=inf, the grad=-9.817157526018171e+162\n",
      "Current iteration=93, the loss=inf, the grad=5.531604693153617e+164\n",
      "Current iteration=94, the loss=inf, the grad=-3.116854384807846e+166\n",
      "Current iteration=95, the loss=inf, the grad=1.756232014937679e+168\n",
      "Current iteration=96, the loss=inf, the grad=-9.895716993792798e+169\n",
      "Current iteration=97, the loss=inf, the grad=5.575870043840111e+171\n",
      "Current iteration=98, the loss=inf, the grad=-3.141796270577995e+173\n",
      "Current iteration=99, the loss=inf, the grad=1.7702858438608275e+175\n",
      "end of the mean_squared_error_gd with w= [-6.59545388e+169  3.31826270e+169  5.00055115e+169  1.92486696e+169\n",
      " -6.21187337e+170 -6.31115329e+170 -6.21093219e+170  1.55492434e+168\n",
      "  8.91484249e+168  6.08852709e+169  8.59820814e+167 -3.05776005e+167\n",
      " -6.21147112e+170  2.16020581e+169 -9.90957146e+165 -7.72222858e+165\n",
      "  2.67009237e+169 -1.85538863e+166  2.65150421e+166  2.08562571e+169\n",
      " -1.08494540e+166  9.19161707e+169  2.07108055e+167 -3.71432314e+170\n",
      " -3.85111368e+170 -3.85114723e+170 -6.22004033e+170 -6.21138659e+170\n",
      " -6.21138780e+170  1.25822889e+169]  and loss= inf\n"
     ]
    }
   ],
   "source": [
    "# testing the mean square gd\n",
    "initial_w = np.zeros(tx_tr.shape[1])\n",
    "max_iters = 100\n",
    "gamma = 0.00001\n",
    "\n",
    "w, loss = mean_squared_error_gd(y_tr, tx_tr, initial_w, max_iters, gamma)\n",
    "\n",
    "print(\"end of the mean_squared_error_gd with w=\",w,\" and loss=\", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3abc58ab-10d3-4a01-b62a-6e3445c65b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end of the least_squares with w= [ 8.03494312e-05 -7.20202273e-03 -6.05417273e-03 -5.47559065e-04\n",
      " -1.93874700e-02  4.73451621e-04 -2.60379054e-02  3.25106300e-01\n",
      " -3.80780282e-05 -2.72724919e+00 -2.21220140e-01  9.50794091e-02\n",
      "  6.40351613e-02  2.73550887e+00 -3.31801241e-04 -9.54325120e-04\n",
      "  2.74026561e+00 -5.34164891e-04  9.73498581e-04  3.69225052e-03\n",
      "  3.54487449e-04 -5.43344598e-04 -3.30448035e-01 -1.40800498e-03\n",
      "  8.31432888e-04  1.02117272e-03 -1.68047416e-03 -5.83664818e-03\n",
      " -1.11087997e-02  2.72770912e+00]  and loss= 0.3396868094770935\n"
     ]
    }
   ],
   "source": [
    "# test least square\n",
    "w, loss = least_squares(y_tr, tx_tr)\n",
    "print(\"end of the least_squares with w=\",w,\" and loss=\", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f09a81-21c9-4587-ba44-9bb03ab90776",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
